<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="kr"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://pelu10075.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://pelu10075.github.io/" rel="alternate" type="text/html" hreflang="kr"/><updated>2025-06-21T06:31:26+00:00</updated><id>https://pelu10075.github.io/feed.xml</id><title type="html">Flu’s Logbook</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Linear Transformation</title><link href="https://pelu10075.github.io/blog/2025/Linear_Transformation/" rel="alternate" type="text/html" title="Linear Transformation"/><published>2025-06-21T00:00:00+00:00</published><updated>2025-06-21T00:00:00+00:00</updated><id>https://pelu10075.github.io/blog/2025/Linear_Transformation</id><content type="html" xml:base="https://pelu10075.github.io/blog/2025/Linear_Transformation/"><![CDATA[<h2 id="linear-transformation--a-function-that-changes-vectors">Linear Transformation — A Function That Changes Vectors</h2> <p>In the previous post, we talked about how matrices can transform vectors.</p> <p>In this post, I will explain what “transformation” means and why it is called linear.</p> <hr/> <h2 id="what-is-a-linear-transformation">What Is a Linear Transformation?</h2> <p>A linear transformation is a function that takes a vector as input and outputs another vector.<br/> But not just any vector transformation qualifies as a linear transformation. It must satisfy two conditions.</p> <p>For a transformation T to be a linear transformation, for any vectors u, v and scalar (real number) c, the following must hold:</p> <ul> <li>Addition preservation: T(u + v) = T(u) + T(v)</li> <li>Scalar multiplication preservation: T(c · u) = c · T(u)</li> </ul> <p>These two conditions mean “linearity”.<br/> Simply put, adding vectors and then transforming must equal transforming them first and then adding.<br/> Similarly, multiplying a vector by a scalar and then transforming must equal transforming first and then scaling.</p> <hr/> <h3 id="linear-transformation--matrix-multiplication">Linear Transformation = Matrix Multiplication</h3> <p>A linear transformation can always be expressed as a matrix multiplication.<br/> That is, it can be written in the form T(x) = A·x, and the matrix A is the essence of the transformation.</p> <p>Therefore, to properly understand linear transformations, you need to understand how matrix multiplication works.</p> <hr/> <h3 id="how-to-compute-matrix-multiplication">How to Compute Matrix Multiplication</h3> <p>Suppose matrix A is:</p> <p>[ A = \begin{bmatrix} a &amp; b \ c &amp; d \end{bmatrix} ]</p> <p>And vector x is:</p> <p>[ X = \begin{bmatrix} x \ y \end{bmatrix} ]</p> <p>Then the product is:</p> <p>[ A×X = \begin{bmatrix} a·x + b·y \ c·x + d·y \end{bmatrix} ]</p> <p>This computation is a core operation used constantly in computer graphics, physics simulation, and deep learning models.</p> <hr/> <h3 id="geometric-meaning-of-linear-transformation">Geometric Meaning of Linear Transformation</h3> <p>Matrix A rotates, scales, shears, or flattens vectors.<br/> For example, the following matrix flattens all vectors onto the x-axis:</p> <p>[ A = \begin{bmatrix} 1 &amp; 0 \ 0 &amp; 0 \end{bmatrix} ]</p> <p>Multiplying any vector results in a vector with a zero y-component. This means all vectors are flattened onto the x-axis.</p> <p>In this way, a matrix acts on space and changes the region where vectors can lie.</p> <hr/> <h2 id="what-is-span">What Is Span?</h2> <p>The span of a set of vectors is the set of all their linear combinations.</p> <p>This may be hard to understand, so for example, suppose we have the following two vectors:</p> <pre><code class="language-plotly">{
  "data": [
    {
      "type": "scatter",
      "mode": "lines+markers+text",
      "x": [0, 1],
      "y": [0, 0],
      "line": { "color": "red", "width": 3 },
      "marker": { "size": 6 },
      "text": ["", "v₁ = [1, 0]"],
      "textposition": "top right",
      "name": "v₁"
    },
    {
      "type": "scatter",
      "mode": "lines+markers+text",
      "x": [0, 0],
      "y": [0, 1],
      "line": { "color": "blue", "width": 3 },
      "marker": { "size": 6 },
      "text": ["", "v₂ = [0, 1]"],
      "textposition": "top left",
      "name": "v₂"
    }
  ],
  "layout": {
    "title": { "text": "Unit Vectors v₁ and v₂" },
    "xaxis": { "range": [-1, 2], "zeroline": true, "title": "x" },
    "yaxis": { "range": [-1, 2], "zeroline": true, "title": "y" },
    "showlegend": false,
    "width": 500,
    "height": 500
  }
}
</code></pre> <p>The span of these two is the entire 2D plane. This is because any vector can be made by multiplying and adding v₁ and v₂ appropriately.</p> <p>On the other hand, if you have two vectors lying in only one direction:</p> <pre><code class="language-plotly">{
  "data": [
    {
      "type": "scatter",
      "mode": "lines+markers+text",
      "x": [0, 1],
      "y": [0, 0],
      "line": { "color": "red", "width": 3 },
      "marker": { "size": 6 },
      "text": ["", "v₁ = [1, 0]"],
      "textposition": "top right",
      "name": "v₁"
    },
    {
      "type": "scatter",
      "mode": "lines+markers+text",
      "x": [0, 2],
      "y": [0, 0],
      "line": { "color": "blue", "width": 3 },
      "marker": { "size": 6 },
      "text": ["", "v₂ = [2, 0]"],
      "textposition": "bottom right",
      "name": "v₂"
    }
  ],
  "layout": {
    "title": { "text": "Vectors v₁ and v₂ on the Plane" },
    "xaxis": { "range": [-1, 3], "zeroline": true, "title": "x" },
    "yaxis": { "range": [-1, 1], "zeroline": true, "title": "y" },
    "showlegend": false
  }
}
</code></pre> <p>Their span is only a single line along the x-axis. Vectors in the same direction can’t create a wider space.</p> <p>So, the span of a set of vectors is the set of all positions they can reach. This concept is closely tied to linear independence, dimension, and basis.</p> <p>This concept is closely tied to linear independence, dimension, and basis.</p> <hr/> <h3 id="why-are-span-and-linear-transformation-connected">Why Are Span and Linear Transformation Connected?</h3> <p>When computing A⋅x for a matrix A, we are effectively sending the input vector into the span of the column vectors of A.</p> <p>That is, the result of a matrix’s linear transformation always lies in the span of its column vectors. This fact is key to understanding solution sets of linear equations, bases, null spaces, etc.</p> <hr/> <h2 id="summary">Summary</h2> <ul> <li> <p>A linear transformation preserves addition and scalar multiplication, and can always be written as a matrix product.</p> </li> <li> <p>Matrix multiplication rotates, transforms, scales, and projects space.</p> </li> <li> <p>Span is the set of all linear combinations that a set of vectors can produce.</p> </li> <li> <p>The result of a linear transformation always lies within the span of the matrix’s column vectors.</p> </li> </ul> <hr/> <p>I created several examples to talk about linear transformations, but due to the nature of blogs, it was hard to show examples of linear transformations being applied. I believe watching 3b1b’s videos will help with intuitive understanding. In the next post, I will discuss eigenvalues and eigenvectors, which are important concepts in linear transformations. Some vectors do not change direction under linear transformation — only their size changes. We’ll look into what those vectors are and why they matter.</p>]]></content><author><name></name></author><category term="Study"/><category term="LinearAlgebra"/><category term="EN"/><summary type="html"><![CDATA[Functions that transform vectors and the idea of span]]></summary></entry><entry><title type="html">선형 변환</title><link href="https://pelu10075.github.io/blog/2025/%EC%84%A0%ED%98%95_%EB%B3%80%ED%99%98/" rel="alternate" type="text/html" title="선형 변환"/><published>2025-06-21T00:00:00+00:00</published><updated>2025-06-21T00:00:00+00:00</updated><id>https://pelu10075.github.io/blog/2025/%EC%84%A0%ED%98%95_%EB%B3%80%ED%99%98</id><content type="html" xml:base="https://pelu10075.github.io/blog/2025/%EC%84%A0%ED%98%95_%EB%B3%80%ED%99%98/"><![CDATA[<h2 id="선형-변환--벡터를-바꾸는-함수">선형 변환 — 벡터를 바꾸는 함수</h2> <p>지난 포스트에선 행렬이 벡터를 변형할 수 있다는 이야기를 하였다.</p> <p>이번 글에서는 ‘변형’이 무슨 의미인지, 그리고 왜 선형(linear)인지 설명하겠다.</p> <hr/> <h2 id="선형-변환이란-무엇인가">선형 변환이란 무엇인가?</h2> <p>선형 변환(linear transformation)은 벡터를 입력으로 받아 또 다른 벡터를 출력하는 함수다. 하지만 아무 벡터 변환이나 선형 변환이 되는 것은 아니다. 반드시 두 가지 조건을 만족해야 한다.</p> <p>어떤 변환 T가 선형 변환이 되려면, 임의의 벡터 u, v와 스칼라(실수) c에 대해 다음 조건이 성립해야 한다.</p> <ul> <li>덧셈 보존: T(u + v) = T(u) + T(v)</li> <li>스칼라 곱 보존: T(c · u) = c · T(u)</li> </ul> <p>이 두 조건은 “선형성(linearity)”을 의미한다. 쉽게 말하면, 벡터들을 먼저 더한 뒤 변환한 것과 각각 변환한 뒤 더한 것이 같아야 하고, 벡터에 먼저 스칼라를 곱한 후 변환한 것과, 변환 후 스칼라를 곱한 것이 같아야 한다.</p> <hr/> <h3 id="선형-변환--행렬-곱">선형 변환 = 행렬 곱</h3> <p>선형 변환은 항상 어떤 행렬 곱으로 표현할 수 있다. 즉, T(x) = A·x 형태로 나타낼 수 있으며, 이 행렬 A가 변환의 본질이다.</p> <p>따라서 선형 변환을 제대로 이해하려면, 행렬 곱의 계산 방법을 알아야 한다.</p> <hr/> <h3 id="행렬-곱-계산-방법">행렬 곱 계산 방법</h3> <p>행렬 A가 다음과 같다고 하자.</p> \[A = \begin{bmatrix} a &amp; b \\ c &amp; d \end{bmatrix}\] <p>벡터 x가 다음과 같을 때,</p> \[X = \begin{bmatrix} x \\ y \end{bmatrix}\] <p>곱셈 결과는 이렇게 나온다.</p> \[A×X = \begin{bmatrix} a·x + b·y \\ c·x + d·y \end{bmatrix}\] <p>이 계산은 컴퓨터 그래픽, 물리 시뮬레이션, 딥러닝 모델에서 매 순간 수행되는 핵심 연산이다.</p> <hr/> <h3 id="선형-변환의-기하학적-의미">선형 변환의 기하학적 의미</h3> <p>행렬 A는 벡터를 회전하거나, 크기를 바꾸거나, 기울이거나, 납작하게 만든다. 예를 들어, 다음 행렬은 모든 벡터를 x축으로 납작하게 누른다.</p> \[A = \begin{bmatrix} 1 &amp; 0 \\ 0 &amp; 0 \end{bmatrix}\] <p>어떤 벡터를 곱해도 결과는 y성분이 0인 벡터가 된다. 이는 모든 벡터가 x축 위로 눌린 것이다.</p> <p>이처럼 행렬은 공간에 작용하며, 벡터들이 놓일 수 있는 범위를 통째로 바꾼다.</p> <hr/> <h2 id="생성span이란">생성(Span)이란?</h2> <p>Span(스팬)은 어떤 벡터 집합이 생성할 수 있는 모든 선형 결합의 집합을 말한다.</p> <p>이렇게 설명하면 이해하기 힘드니, 예를 들자면, 다음 두 벡터가 있다고 하자.</p> <pre><code class="language-plotly">{
  "data": [
    {
      "type": "scatter",
      "mode": "lines+markers+text",
      "x": [0, 1],
      "y": [0, 0],
      "line": { "color": "red", "width": 3 },
      "marker": { "size": 6 },
      "text": ["", "v₁ = [1, 0]"],
      "textposition": "top right",
      "name": "v₁"
    },
    {
      "type": "scatter",
      "mode": "lines+markers+text",
      "x": [0, 0],
      "y": [0, 1],
      "line": { "color": "blue", "width": 3 },
      "marker": { "size": 6 },
      "text": ["", "v₂ = [0, 1]"],
      "textposition": "top left",
      "name": "v₂"
    }
  ],
  "layout": {
    "title": { "text": "Unit Vectors v₁ and v₂" },
    "xaxis": { "range": [-1, 2], "zeroline": true, "title": "x" },
    "yaxis": { "range": [-1, 2], "zeroline": true, "title": "y" },
    "showlegend": false,
    "width": 500,
    "height": 500
  }
}
</code></pre> <p>이 둘의 Span은 2차원 평면 전체다. 왜냐하면 모든 벡터는 v₁과 v₂를 적절히 곱하고 더해서 만들 수 있기 때문이다.</p> <p>반대로 다음처럼 한 방향에만 있는 벡터 두 개:</p> <pre><code class="language-plotly">{
  "data": [
    {
      "type": "scatter",
      "mode": "lines+markers+text",
      "x": [0, 1],
      "y": [0, 0],
      "line": { "color": "red", "width": 3 },
      "marker": { "size": 6 },
      "text": ["", "v₁ = [1, 0]"],
      "textposition": "top right",
      "name": "v₁"
    },
    {
      "type": "scatter",
      "mode": "lines+markers+text",
      "x": [0, 2],
      "y": [0, 0],
      "line": { "color": "blue", "width": 3 },
      "marker": { "size": 6 },
      "text": ["", "v₂ = [2, 0]"],
      "textposition": "bottom right",
      "name": "v₂"
    }
  ],
  "layout": {
    "title": { "text": "Vectors v₁ and v₂ on the Plane" },
    "xaxis": { "range": [-1, 3], "zeroline": true, "title": "x" },
    "yaxis": { "range": [-1, 1], "zeroline": true, "title": "y" },
    "showlegend": false
  }
}
</code></pre> <p>이들의 Span은 x축 위의 직선 하나뿐이다. 같은 방향의 벡터끼리는 더해봤자 더 넓은 공간을 만들 수 없다.</p> <p>즉, 벡터들의 Span이란 그 벡터들이 <strong>닿을 수 있는 모든 위치</strong>의 집합이다. 이 개념은 선형 독립, 차원, 기저 등과 밀접하게 연결된다.</p> <hr/> <h3 id="왜-span과-선형-변환이-연결되는가">왜 Span과 선형 변환이 연결되는가?</h3> <p>어떤 행렬 A에 대해 A·x를 구한다고 했을 때, 결국 A는 자기 열벡터들의 Span 속으로 입력 벡터를 ‘보내는’ 역할을 한다.</p> <p>즉, 행렬의 선형 변환 결과는 행렬 열벡터들의 Span 안에 항상 존재한다. 이 사실은 해를 갖는 연립방정식, 기저, 영공간(null space) 등을 이해할 때 핵심이 된다.</p> <hr/> <h2 id="요약">요약</h2> <ul> <li> <p>선형 변환은 덧셈과 스칼라 곱을 보존하는 변환이며, 항상 행렬 곱으로 나타낼 수 있다.</p> </li> <li> <p>행렬 곱은 공간을 회전, 변형, 축소, 투영하는 역할을 한다.</p> </li> <li> <p>Span은 벡터들이 만들어낼 수 있는 모든 선형 결합의 집합이다.</p> </li> <li> <p>선형 변환 결과는 항상 행렬의 열벡터들의 Span 안에 위치한다.</p> </li> </ul> <hr/> <p>선형 변환에 대해 이야기 해보기 위해 여러 예제를 만들어 보았으나, 블로그의 특성상 선형 변환이 적용되는 예시를 보여주기 어려웠다. <strong>3b1b</strong>의 영상을 보고 직관적으로 이해하는 편이 학습에 도움이 될 것이라 생각한다. 다음 글에서는 선형 변환에서 중요한 개념인 <strong>고유값(eigenvalue)</strong>과 <strong>고유벡터(eigenvector)</strong>에 대해 다룬다. 특정 벡터는 선형 변환을 거쳐도 방향이 바뀌지 않고 크기만 달라지는데, 그런 벡터가 무엇이며 왜 중요한지 살펴보겠다.</p>]]></content><author><name></name></author><category term="Study"/><category term="LinearAlgebra"/><category term="KR"/><summary type="html"><![CDATA[벡터를 변환하는 함수와 생성에 대해]]></summary></entry><entry><title type="html">Vectors and Matrices</title><link href="https://pelu10075.github.io/blog/2025/Vectors_and_Matrices/" rel="alternate" type="text/html" title="Vectors and Matrices"/><published>2025-06-18T14:00:00+00:00</published><updated>2025-06-18T14:00:00+00:00</updated><id>https://pelu10075.github.io/blog/2025/Vectors_and_Matrices</id><content type="html" xml:base="https://pelu10075.github.io/blog/2025/Vectors_and_Matrices/"><![CDATA[<h2 id="vectors-and-matrices--the-language-of-linear-algebra">Vectors and Matrices — The Language of Linear Algebra</h2> <p>Now that we’ve clarified the terminology, it’s time to meet the main characters of linear algebra: <strong>vectors</strong> and <strong>matrices</strong>.</p> <p>They are not just lists or tables of numbers.</p> <p>They are <strong>tools for representing and transforming data</strong>,</p> <p>used in <strong>3D graphics, machine learning, physics, statistics</strong>, and many other real-world fields.</p> <hr/> <h2 id="what-is-a-vector">What Is a Vector?</h2> <p>A vector is an <strong>ordered list of numbers</strong>.</p> <p>In linear algebra, we usually write them as <strong>column vectors</strong>, vertically aligned like this:</p> \[\vec{v} = \begin{bmatrix} 2 \\ -1 \\ 4 \end{bmatrix}\] <p>This is a 3-dimensional vector —</p> <p>three numbers (2, -1, 4) grouped together as a single entity.</p> <p>But a vector is more than just a list.</p> <p>It can represent things like:</p> <ul> <li>A position in space (a point)</li> <li>A direction and magnitude (e.g., force, velocity)</li> <li>A bundle of features (e.g., input values in machine learning)</li> </ul> <hr/> <h3 id="example-of-a-2d-vector">Example of a 2D Vector</h3> \[\vec{v} = \begin{bmatrix} 3 \\ 4 \end{bmatrix}\] <p>This vector points to the location (3, 4) in 2D space.</p> <p>Its <strong>magnitude (length)</strong> is:</p> \[\|\vec{v}\| = \sqrt{3^2 + 4^2} = 5\] <p>In other words, it’s a <strong>length-5 arrow from the origin to (3, 4)</strong>.</p> <hr/> <h2 id="what-is-a-matrix">What Is a Matrix?</h2> <p>A matrix is a <strong>rectangular array</strong> of numbers arranged in rows and columns.</p> <p>Example: a 2×2 matrix</p> \[A = \begin{bmatrix} 1 &amp; 2 \\ 3 &amp; 4 \end{bmatrix}\] <p>There are two main ways to understand a matrix:</p> <h3 id="1-a-collection-of-vectors">1. A Collection of Vectors</h3> <p>Each <strong>column (or row)</strong> of the matrix can be seen as an individual vector.</p> <p>So a matrix is like a bundle of multiple vectors.</p> <h3 id="2-a-function-that-transforms-vectors">2. A Function That Transforms Vectors</h3> <p>More importantly, a <strong>matrix is a tool that transforms one vector into another</strong>.</p> <p>This is called a <strong>linear transformation</strong>.</p> <hr/> <h3 id="example-matrix--vector">Example: Matrix × Vector</h3> <p>Let’s multiply a matrix and a vector:</p> \[A = \begin{bmatrix} 1 &amp; 2 \\ 3 &amp; 4 \end{bmatrix}, \quad \vec{x} = \begin{bmatrix} 5 \\ 6 \end{bmatrix}\] <p>Then:</p> \[A\vec{x} = \begin{bmatrix} 1×5 + 2×6 \\ 3×5 + 4×6 \end{bmatrix} = \begin{bmatrix} 17 \\ 39 \end{bmatrix}\] <p>So matrix <strong>A</strong> has transformed vector <strong>x</strong> into a new vector.</p> <hr/> <h2 id="why-vectors-and-matrices-matter">Why Vectors and Matrices Matter</h2> <p>These two concepts are the <strong>foundation</strong> of almost every topic in linear algebra:</p> <ul> <li>Systems of linear equations</li> <li>Matrix equations</li> <li>Linear transformations</li> <li>Eigenvalues and eigenvectors</li> <li>Deep learning</li> <li>3D simulation and graphics</li> </ul> <p>To summarize:</p> <p><strong>Vectors represent data</strong>, <strong>Matrices represent how we work with that data</strong>.</p> <hr/> <p>In the next post, we’ll dive deeper into <strong>linear transformations</strong> — exploring how matrices change vectors using geometric intuition and visual examples.</p>]]></content><author><name></name></author><category term="Study"/><category term="LinearAlgebra"/><category term="EN"/><summary type="html"><![CDATA[What are vectors and matrices, and why do they matter?]]></summary></entry><entry><title type="html">벡터와 행렬</title><link href="https://pelu10075.github.io/blog/2025/%EB%B2%A1%ED%84%B0%EC%99%80_%ED%96%89%EB%A0%AC/" rel="alternate" type="text/html" title="벡터와 행렬"/><published>2025-06-18T14:00:00+00:00</published><updated>2025-06-18T14:00:00+00:00</updated><id>https://pelu10075.github.io/blog/2025/%EB%B2%A1%ED%84%B0%EC%99%80_%ED%96%89%EB%A0%AC</id><content type="html" xml:base="https://pelu10075.github.io/blog/2025/%EB%B2%A1%ED%84%B0%EC%99%80_%ED%96%89%EB%A0%AC/"><![CDATA[<h2 id="벡터와-행렬--선형대수학의-언어">벡터와 행렬 — 선형대수학의 언어</h2> <p>이제 용어들을 정리했으니, 선형대수학의 핵심 주인공인 <strong>벡터</strong>와 <strong>행렬</strong>을 만나볼 차례다.</p> <p>이 둘은 단순히 숫자를 나열한 리스트나 표가 아니다.</p> <p><strong>데이터를 표현하고 변환하는 도구</strong>이며,</p> <p><strong>3D 그래픽, 머신러닝, 물리학, 통계학</strong> 등 실생활 곳곳에서 사용된다.</p> <hr/> <h2 id="벡터란">벡터란?</h2> <p>벡터는 숫자들의 <strong>순서 있는 나열</strong>이다.</p> <p>선형대수학에서는 보통 <strong>세로로 나열한 열벡터</strong> 형태로 쓴다.</p> \[\vec{v} = \begin{bmatrix} 2 \\ -1 \\ 4 \end{bmatrix}\] <p>이건 3차원 벡터다.</p> <p>숫자 3개(2, -1, 4)가 하나의 덩어리로 묶여 있는 것.</p> <p>하지만 벡터는 단순한 리스트 이상이다.</p> <p>다음과 같이 해석할 수 있다:</p> <ul> <li>공간상의 위치 (점)</li> <li>방향과 크기 (예: 힘, 속도)</li> <li>특성값의 묶음 (예: 머신러닝 입력값)</li> </ul> <hr/> <h3 id="2차원-벡터-예시">2차원 벡터 예시</h3> \[\vec{v} = \begin{bmatrix} 3 \\ 4 \end{bmatrix}\] <p>이 벡터는 2D 공간에서 (3, 4) 지점을 가리킨다.</p> <p>길이(크기)는 다음과 같다:</p> \[\|\vec{v}\| = \sqrt{3^2 + 4^2} = 5\] <p>즉, 원점에서 (3, 4)로 향하는 <strong>길이 5짜리 화살표</strong>라고 보면 된다.</p> <hr/> <h2 id="행렬이란">행렬이란?</h2> <p>행렬은 숫자들을 행과 열로 배열한 <strong>직사각형 형태의 표</strong>다.</p> \[A = \begin{bmatrix} 1 &amp; 2 \\ 3 &amp; 4 \end{bmatrix}\] <p>행렬은 크게 두 가지 관점에서 볼 수 있다:</p> <h3 id="1-벡터의-모음">1. 벡터의 모음</h3> <p>행렬의 각 열(또는 행)을 벡터 하나로 보면, 여러 벡터를 모아놓은 집합이다.</p> <h3 id="2-벡터를-변환하는-함수">2. 벡터를 변환하는 함수</h3> <p>더 중요한 관점은, <strong>행렬은 벡터를 다른 벡터로 바꾸는 장치</strong>라는 것.</p> <p>이걸 선형 변환(linear transformation)이라고 한다.</p> <hr/> <h3 id="행렬--벡터-예시">행렬 × 벡터 예시</h3> <p>행렬과 벡터를 곱해보자,</p> \[A = \begin{bmatrix} 1 &amp; 2 \\ 3 &amp; 4 \end{bmatrix}, \quad \vec{x} = \begin{bmatrix} 5 \\ 6 \end{bmatrix}\] <p>곱하면,</p> \[A\vec{x} = \begin{bmatrix} 1×5 + 2×6 \\ 3×5 + 4×6 \end{bmatrix} = \begin{bmatrix} 17 \\ 39 \end{bmatrix}\] <p>즉, 행렬 <strong>A</strong>가 벡터 <strong>x</strong>를 변환해서 새로운 벡터로 만든 것이다.</p> <hr/> <h2 id="벡터와-행렬이-중요한-이유">벡터와 행렬이 중요한 이유</h2> <p>이 두 개념은 선형대수학의 거의 모든 주제의 <strong>기초</strong>가 된다:</p> <ul> <li>연립방정식</li> <li>행렬 방정식</li> <li>선형 변환</li> <li>고유값/고유벡터</li> <li>딥러닝</li> <li>3D 시뮬레이션 및 그래픽</li> </ul> <p>요약하면,</p> <p><strong>벡터는 데이터</strong>이고 <strong>행렬은 그 데이터를 다루는 방식</strong>이다.</p> <hr/> <p>다음 포스트에서는 선형 변환(linear transformation)을 본격적으로 다룬다.</p> <p>행렬이 벡터를 어떻게 변형하는지를 기하학적 예시와 함께 설명해볼 예정이다.</p>]]></content><author><name></name></author><category term="Study"/><category term="LinearAlgebra"/><category term="KR"/><summary type="html"><![CDATA[벡터와 행렬이란 무엇이며, 왜 중요한가?]]></summary></entry><entry><title type="html">Common Terminology in Linear Algebra</title><link href="https://pelu10075.github.io/blog/2025/Common_Terminology_in_Linear_Algebra/" rel="alternate" type="text/html" title="Common Terminology in Linear Algebra"/><published>2025-06-15T12:10:00+00:00</published><updated>2025-06-15T12:10:00+00:00</updated><id>https://pelu10075.github.io/blog/2025/Common_Terminology_in_Linear_Algebra</id><content type="html" xml:base="https://pelu10075.github.io/blog/2025/Common_Terminology_in_Linear_Algebra/"><![CDATA[<h2 id="the-first-barrier-in-linear-algebra-terminology">The First Barrier in Linear Algebra: Terminology</h2> <p>When I first started studying linear algebra, the biggest obstacle wasn’t complicated calculations or formulas.</p> <p>Rather, it was the <strong>terms</strong> like <em>vector</em>, <em>linear independence</em>, <em>eigenvalue</em>, and <em>null space</em> that felt more difficult.</p> <p>They’re just words, but since I couldn’t grasp their meanings, the formulas didn’t make sense either.</p> <p>I kept wondering, “Are these math terms? Physics terms? Or just some kind of technical jargon?”</p> <p>So, before diving into linear algebra seriously,</p> <p>I decided to organize some <strong>basic terminology</strong> for those like me who get stuck on the language first.</p> <p>I believe that if you understand the <strong>words</strong> before jumping into the <strong>concepts and formulas</strong>, studying becomes much easier.</p> <hr/> <h2 id="glossary-of-linear-algebra-terms">Glossary of Linear Algebra Terms</h2> <hr/> <h3 id="scalar">Scalar</h3> <p>A single number. Literally, just a number.</p> <p>Often appears when multiplying with vectors or matrices.</p> \[\ 3,\ -1,\ 0.5,\ \pi\] <hr/> <h3 id="vector">Vector</h3> <p>A list of numbers arranged in a sequence.</p> <p>In 2D, it can feel like an arrow with direction and magnitude.</p> \[\vec{v} = \begin{bmatrix} 2 \\ -1 \end{bmatrix} \quad \text{or} \quad (2,\ -1)\] <hr/> <h3 id="matrix">Matrix</h3> <p>A rectangular arrangement of numbers.</p> <p>Think of it like an Excel spreadsheet, made up of rows and columns.</p> <p>In later sections, we’ll mostly deal with <strong>vectors in matrix form</strong>.</p> \[A = \begin{bmatrix} 1 &amp; 2 \\ 3 &amp; 4 \end{bmatrix}\] <p>Most of the following terms are based on matrices.</p> <hr/> <h3 id="transpose-of-a-matrix">Transpose of a Matrix</h3> <p>A matrix with its rows and columns swapped.</p> \[A = \begin{bmatrix} 1 &amp; 2 \\ 3 &amp; 4 \end{bmatrix} \Rightarrow A^T = \begin{bmatrix} 1 &amp; 3 \\ 2 &amp; 4 \end{bmatrix}\] <hr/> <h3 id="identity-matrix">Identity Matrix</h3> <p>The “1” of matrices.</p> <p>It has 1s on the main diagonal and 0s elsewhere.</p> <p>Usually denoted by I.</p> \[I = \begin{bmatrix} 1 &amp; 0 \\ 0 &amp; 1 \end{bmatrix}\] <hr/> <h3 id="square-matrix">Square Matrix</h3> <p>A matrix with the same number of rows and columns.</p> \[\begin{bmatrix} a &amp; b \\ c &amp; d \end{bmatrix}, \ \begin{bmatrix} a &amp; b &amp; c \\ d &amp; e &amp; f \\ g &amp; h &amp; i \end{bmatrix} \ ...\] <hr/> <h3 id="symmetric-matrix">Symmetric Matrix</h3> <p>A matrix that stays the same even after transposing.</p> <p>That is,</p> \[A = A^T\] <hr/> <h3 id="row-echelon-form">Row Echelon Form</h3> <p>A step-by-step matrix form used in Gaussian elimination.</p> <p>Helpful for solving systems of equations.</p> \[\begin{bmatrix} a &amp; b &amp; c \\ 0 &amp; d &amp; e \\ 0 &amp; 0 &amp; 0 \end{bmatrix}\] <p>We’ll cover the detailed conditions later in a document about <strong>Gauss-Jordan elimination</strong>.</p> <hr/> <h3 id="zero-matrix">Zero Matrix</h3> <p>A matrix where all the elements are 0.</p> \[\begin{bmatrix} 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 \end{bmatrix}\] <hr/> <h3 id="diagonal-matrix">Diagonal Matrix</h3> <p>Only the main diagonal has values; all other elements are 0.</p> \[\begin{bmatrix} 2 &amp; 0 \\ 0 &amp; 5 \end{bmatrix}\] <hr/> <h3 id="sparse-matrix">Sparse Matrix</h3> <p>A matrix in which most elements are 0.</p> <p>Common in big data and graph theory applications.</p> <hr/> <h3 id="triangular-matrix">Triangular Matrix</h3> <p>A matrix where one side (upper or lower) is filled with 0s, forming a triangle shape.</p> <p>Common in Gaussian elimination, LU decomposition, and solving linear systems.</p> <hr/> <h3 id="upper-triangular-matrix">Upper Triangular Matrix</h3> <p>All elements below the main diagonal are 0.</p> <p>Only the upper part has values.</p> \[\begin{bmatrix} 1 &amp; 2 &amp; 3 \\ 0 &amp; 4 &amp; 5 \\ 0 &amp; 0 &amp; 6 \end{bmatrix}\] <hr/> <h3 id="lower-triangular-matrix">Lower Triangular Matrix</h3> <p>All elements above the main diagonal are 0.</p> <p>Only the lower part has values.</p> \[\begin{bmatrix} 1 &amp; 0 &amp; 0 \\ 2 &amp; 3 &amp; 0 \\ 4 &amp; 5 &amp; 6 \end{bmatrix}\] <hr/> <p>You don’t need to memorize all the terms above.</p> <p>If you come across difficult words without explanations, feel free to come back and refer to this guide.</p>]]></content><author><name></name></author><category term="Study"/><category term="LinearAlgebra"/><category term="EN"/><summary type="html"><![CDATA[Basic Terminology to Know Before Learning Linear Algebra]]></summary></entry><entry><title type="html">선형대수학에서 주로 쓰이는 용어</title><link href="https://pelu10075.github.io/blog/2025/%EC%84%A0%ED%98%95%EB%8C%80%EC%88%98%ED%95%99%EC%97%90%EC%84%9C_%EC%A3%BC%EB%A1%9C_%EC%93%B0%EC%9D%B4%EB%8A%94_%EC%9A%A9%EC%96%B4/" rel="alternate" type="text/html" title="선형대수학에서 주로 쓰이는 용어"/><published>2025-06-15T12:10:00+00:00</published><updated>2025-06-15T12:10:00+00:00</updated><id>https://pelu10075.github.io/blog/2025/%EC%84%A0%ED%98%95%EB%8C%80%EC%88%98%ED%95%99%EC%97%90%EC%84%9C_%EC%A3%BC%EB%A1%9C_%EC%93%B0%EC%9D%B4%EB%8A%94_%EC%9A%A9%EC%96%B4</id><content type="html" xml:base="https://pelu10075.github.io/blog/2025/%EC%84%A0%ED%98%95%EB%8C%80%EC%88%98%ED%95%99%EC%97%90%EC%84%9C_%EC%A3%BC%EB%A1%9C_%EC%93%B0%EC%9D%B4%EB%8A%94_%EC%9A%A9%EC%96%B4/"><![CDATA[<h2 id="선형대수학의-1차적인-장벽-용어">선형대수학의 1차적인 장벽: 용어</h2> <p>선형대수학을 처음 공부할 때, 가장 먼저 막혔던 건 복잡한 계산이나 수식이 아니었다.</p> <p>오히려 ‘벡터’, ‘선형 독립’, ‘고유값’, ‘영공간’ 같은 <strong>용어</strong>들이 더 어렵게 느껴졌다.</p> <p>그냥 단어일 뿐인데, 무슨 뜻인지 감이 안 오니 수식도 눈에 안 들어왔다.</p> <p>“이건 수학 용어야? 물리 용어야? 아니면 그냥 전문 용어인 거야?” 하는 생각도 들었다.</p> <p>그래서 선형대수학을 본격적으로 배우기 전에,</p> <p>나처럼 <strong>용어에서 막히는 사람들</strong>을 위해 <strong>기본적인</strong> 용어들부터 정리하려고 한다.</p> <p>처음부터 개념과 수식에 뛰어들기보다는, <strong>말을 이해하고 나서 배우면</strong> 공부가 훨씬 쉬워진다고 생각하기 때문이다.</p> <h2 id="선형대수학-용어-정리">선형대수학 용어 정리</h2> <hr/> <h3 id="스칼라">스칼라</h3> <p>하나의 수. 말 그대로 그냥 숫자다.</p> <p>벡터나 행렬에 곱할 때 많이 등장한다.</p> \[\ 3,\ -1,\ 0.5,\ \pi\] <hr/> <h3 id="벡터">벡터</h3> <p>숫자 여러 개를 쭉 나열한 것이다.</p> <p>2차원에서는 방향과 크기를 가지는 ‘화살표’ 같은 느낌이다.</p> \[\vec{v} = \begin{bmatrix} 2 \\ -1 \end{bmatrix} \quad \text{or} \quad (2,\ -1)\] <hr/> <h3 id="행렬">행렬</h3> <p>숫자들을 직사각형으로 배열한 것이다.</p> <p>엑셀처럼 행과 열로 이루어져 있다.</p> <p>이후 상술할 문서에서는 <strong>행렬 형태로 나타낸 벡터</strong>를 주로 다룰 것이다.</p> \[A = \begin{bmatrix} 1 &amp; 2 \\ 3 &amp; 4 \end{bmatrix}\] <p>그리고 이후의 대부분의 용어는 <strong>행렬에 기반</strong>을 두고 있다.</p> <hr/> <h3 id="전치-행렬">전치 행렬</h3> <p>행과 열을 뒤집은 행렬이다.</p> \[A = \begin{bmatrix} 1 &amp; 2 \\ 3 &amp; 4 \end{bmatrix} \Rightarrow A^T = \begin{bmatrix} 1 &amp; 3 \\ 2 &amp; 4 \end{bmatrix}\] <hr/> <h3 id="단위-행렬">단위 행렬</h3> <p>행렬의 ‘1’ 같은 존재이다.</p> <p>주대각선엔 1, 나머지는 0을 배치하면 단위 행렬이다.</p> <p>보통 I로 표기한다.</p> \[I = \begin{bmatrix} 1 &amp; 0 \\ 0 &amp; 1 \end{bmatrix}\] <hr/> <h3 id="정방-행렬">정방 행렬</h3> <p>행과 열의 수가 같은 행렬이다.</p> \[\begin{bmatrix} a &amp; b \\ c &amp; d \end{bmatrix}, \ \begin{bmatrix} a &amp; b &amp; c \\ d &amp; e &amp; f \\ g &amp; h &amp; i \end{bmatrix} \ ...\] <hr/> <h3 id="대칭-행렬">대칭 행렬</h3> <p>전치해도 똑같은 행렬이다. 즉,</p> \[A = A^T\] <hr/> <h3 id="행-사다리꼴">행 사다리꼴</h3> <p>가우스 소거법에서 나오는 단계적인 행렬 형태이다.</p> <p>해를 구할 때 유용하다.</p> \[\begin{bmatrix} a &amp; b &amp; c \\ 0 &amp; d &amp; e \\ 0 &amp; 0 &amp; 0 \end{bmatrix}\] <p>자세한 조건은 이후 작성할 <strong>가우스-조던 소거법</strong> 문서에서 다루겠다.</p> <hr/> <h3 id="영-행렬">영 행렬</h3> <p>모든 원소가 0인 행렬이다.</p> \[\begin{bmatrix} 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 \end{bmatrix}\] <hr/> <h3 id="대각-행렬">대각 행렬</h3> <p>주대각선만 값이 있고, 나머지는 모두 0인 행렬이다.</p> \[\begin{bmatrix} 2 &amp; 0 \\ 0 &amp; 5 \end{bmatrix}\] <hr/> <h3 id="희소-행렬">희소 행렬</h3> <p>대부분의 원소가 0인 행렬이다.</p> <p>빅데이터나 그래프 이론에서 자주 쓰인다.</p> <hr/> <h3 id="삼각-행렬">삼각 행렬</h3> <p>말 그대로 한쪽이 삼각형처럼 0으로 채워진 행렬이다.</p> <p>보통 가우스 소거법, LU 분해, 연립방정식 해법에서 많이 나온다.</p> <hr/> <h3 id="상삼각-행렬">상삼각 행렬</h3> <p>주대각선 아래쪽이 모두 0인 행렬이다.</p> <p>위쪽만 값이 있고, 아래는 다 0이다.</p> \[\begin{bmatrix} 1 &amp; 2 &amp; 3 \\ 0 &amp; 4 &amp; 5 \\ 0 &amp; 0 &amp; 6 \end{bmatrix}\] <hr/> <h3 id="하삼각-행렬">하삼각 행렬</h3> <p>주대각선 위쪽이 모두 0인 행렬이다.</p> <p>아래쪽만 값이 있고, 위는 다 0이다.</p> \[\begin{bmatrix} 1 &amp; 0 &amp; 0 \\ 2 &amp; 3 &amp; 0 \\ 4 &amp; 5 &amp; 6 \end{bmatrix}\] <hr/> <p>위에서 다룬 개념들을 전부 외워둘 필요는 없다.</p> <p>설명 없이 어려운 용어가 등장하면, 이 문서를 다시 참고하길 바란다.</p>]]></content><author><name></name></author><category term="Study"/><category term="LinearAlgebra"/><category term="KR"/><summary type="html"><![CDATA[선형대수학을 배우기 앞서 알아야 할 용어]]></summary></entry><entry><title type="html">What is Linear Algebra?</title><link href="https://pelu10075.github.io/blog/2025/What-is-Linear-Algebra/" rel="alternate" type="text/html" title="What is Linear Algebra?"/><published>2025-06-10T14:10:00+00:00</published><updated>2025-06-10T14:10:00+00:00</updated><id>https://pelu10075.github.io/blog/2025/What%20is%20Linear%20Algebra</id><content type="html" xml:base="https://pelu10075.github.io/blog/2025/What-is-Linear-Algebra/"><![CDATA[<p>Linear algebra is a branch of mathematics centered around <strong>vectors</strong>, <strong>matrices</strong>, and <strong>linear transformations</strong>. These theories are not confined to math textbooks—they are actively used in fields like <strong>computer science</strong>, <strong>economics</strong>, and <strong>natural sciences</strong>.</p> <p>In particular, <strong>computer science</strong> relies on linear algebra as a foundational component for core technologies such as artificial intelligence, graphics, and data analysis.</p> <p>In this blog series, I aim to <strong>explain the concepts and applications of linear algebra from a computer science perspective</strong>, in an approachable way. Even if you’re not familiar with mathematics, the posts will be structured to help you understand through real-world applications and examples.</p> <p>Since there’s some space left in this introductory post, I’ll also cover the historical background of linear algebra, its applications, and an outline of future posts.</p> <hr/> <h2 id="historical-background-of-linear-algebra">Historical Background of Linear Algebra</h2> <p>Although linear algebra is a key part of modern mathematics, its roots go back as far as 3000 BCE. The terminology of vectors and matrices is relatively modern, but the ideas themselves existed long ago.</p> <h3 id="1-ancient-babylon-3000-bce">1. Ancient Babylon (~3000 BCE)</h3> <p>The Babylonians were capable of solving systems of equations up to the third degree. While they didn’t use symbolic notation, they had algorithms equivalent to solving linear equations.</p> <ul> <li>Source: Victor J. Katz, <em>A History of Mathematics: An Introduction</em>, Addison-Wesley, 2009.</li> </ul> <h3 id="2-ancient-china--the-nine-chapters-on-the-mathematical-art-2nd-century-bce">2. Ancient China – <em>The Nine Chapters on the Mathematical Art</em> (~2nd century BCE)</h3> <p>The chapter “Fangcheng” in <em>The Nine Chapters</em> describes a method for solving systems of linear equations, similar to Gaussian elimination.</p> <ul> <li>Source: Joseph Needham, <em>Science and Civilisation in China, Volume 3</em>, Cambridge University Press, 1959.</li> </ul> <h3 id="3-18th19th-century-europe--birth-of-matrix-theory">3. 18th–19th Century Europe – Birth of Matrix Theory</h3> <p><strong>Gabriel Cramer (1750)</strong>: Introduced Cramer’s Rule for solving systems of linear equations.</p> <p><strong>Carl Friedrich Gauss (1800s)</strong>: Formalized the <strong>Gaussian elimination</strong> method.</p> <p><strong>Augustin-Louis Cauchy (1820s)</strong>: Organized the concepts of matrices and determinants.</p> <p><strong>Arthur Cayley &amp; James Sylvester (1850s)</strong>: Formalized the concept of matrices and laid the groundwork for matrix operations and eigenvalue theory.</p> <ul> <li>Source: Thomas Hawkins, <em>Emergence of the Theory of Lie Groups</em>, Springer, 2000; Karen Hunger Parshall, <em>James Joseph Sylvester: Jewish Mathematician in a Victorian World</em>, Johns Hopkins University Press, 2006.</li> </ul> <h3 id="4-development-of-modern-linear-algebra-earlymid-20th-century">4. Development of Modern Linear Algebra (Early–Mid 20th Century)</h3> <p>Mathematicians such as <strong>David Hilbert</strong> and <strong>Emmy Noether</strong> connected linear algebra with <strong>abstract algebra</strong> and <strong>functional analysis</strong>, and it became a key language in <strong>quantum mechanics</strong>.</p> <ul> <li>Source: I. M. Gelfand, <em>Lectures on Linear Algebra</em>, Dover Publications, 1989.</li> </ul> <hr/> <h2 id="why-linear-algebra-matters">Why Linear Algebra Matters</h2> <ol> <li> <p>Machine Learning / Deep Learning<br/> Neural networks use vectors and matrices to represent weights, input data, and more.</p> </li> <li> <p>Computer Graphics<br/> 3D transformations like rotation, scaling, and translation are represented using matrices.</p> </li> <li> <p>Physics<br/> In quantum mechanics, vector spaces are used to describe physical states.</p> </li> <li> <p>Statistics / Data Analysis<br/> Tools like covariance matrices and principal component analysis (PCA) rely heavily on linear algebra.</p> </li> </ol> <hr/> <h2 id="upcoming-posts">Upcoming Posts</h2> <ol> <li>Common Terminology in Linear Algebra</li> <li>Vectors and Matrices</li> <li>Linear Transformations</li> <li>Determinants</li> <li>Cross Product and Dot Product</li> <li>Eigenvalues and Eigenvectors</li> <li>Solving Systems of Linear Equations</li> <li>LU Decomposition</li> <li>Gauss–Jordan Elimination</li> <li>Eigenvalue Decomposition</li> <li>Linear Regression</li> </ol> <hr/> <p>This post focused on summarizing the overall concepts and historical background of linear algebra. Starting with the next post, we will explore each topic in more detail.</p>]]></content><author><name></name></author><category term="Study"/><category term="LinearAlgebra"/><category term="EN"/><summary type="html"><![CDATA[Introduction to Linear Algebra]]></summary></entry><entry><title type="html">선형대수학이란?</title><link href="https://pelu10075.github.io/blog/2025/%EC%84%A0%ED%98%95%EB%8C%80%EC%88%98%ED%95%99%EC%9D%B4%EB%9E%80/" rel="alternate" type="text/html" title="선형대수학이란?"/><published>2025-06-10T14:10:00+00:00</published><updated>2025-06-10T14:10:00+00:00</updated><id>https://pelu10075.github.io/blog/2025/%EC%84%A0%ED%98%95%EB%8C%80%EC%88%98%ED%95%99%EC%9D%B4%EB%9E%80</id><content type="html" xml:base="https://pelu10075.github.io/blog/2025/%EC%84%A0%ED%98%95%EB%8C%80%EC%88%98%ED%95%99%EC%9D%B4%EB%9E%80/"><![CDATA[<p>선형대수학은 <strong>벡터</strong>, <strong>행렬</strong>, 그리고 <strong>선형 변환</strong> 등을 중심으로 전개되는 수학의 한 분야이다. 이 이론들은 단순히 수학 교과서에 머무르지 않고, <strong>컴퓨터과학</strong>, <strong>경제학</strong>, <strong>자연과학</strong> 등 여러 분야에서 실제로 활용된다.</p> <p>특히 <strong>컴퓨터과학</strong>에서는 인공지능, 그래픽스, 데이터 분석 등 핵심 기술의 기반이 되는 수학이기도 하다.</p> <p>이 블로그 시리즈에서는 <strong>컴퓨터과학을 중심으로 선형대수학의 개념과 활용</strong>을 쉽게 풀어보고자 한다. 수학에 익숙하지 않아도, 실제 적용 사례와 함께 이해할 수 있도록 구성할 예정이다.</p> <p>그리고 아래는 블로그에 넣을게 없어서 역사적 배경과 사용처, 이후 예정된 포스트에 대해 다루도록 하겠다.</p> <hr/> <h2 id="선형대수학의-역사적-배경">선형대수학의 역사적 배경</h2> <p>선형대수학은 현대 수학의 핵심 분야 중 하나이지만, 그 뿌리는 기원전 3000년까지 거슬러 올라간다. 벡터와 행렬이라는 용어는 현대에 들어와 정립되었지만, 그 개념은 고대 바빌로니아에서 부터 존재했다.</p> <h3 id="1-고대-바빌로니아-기원전-3000년">1. 고대 바빌로니아 (~기원전 3000년)</h3> <p>바빌로니아인들은 2차에서 3차에 이르는 연립방정식을 풀 수 있었다. 문자 기호는 사용하지 않았으나, 이미 선형 방정식을 푸는 알고리즘을 알고 있었다 할 수 있다.</p> <ul> <li>출처: Victor J. Katz, <em>A History of Mathematics: An Introduction</em>, Addison-Wesley, 2009.</li> </ul> <h3 id="2-고대-중국---구장산술九章算術-기원전-2세기">2. 고대 중국 - 『구장산술(九章算術)』 (~기원전 2세기)</h3> <p>『구장산술』의 ‘방정’ 장에서는 가우스 소거법과 유사한 방식의 선형 방정식 풀이법이 소개되어 있다.</p> <ul> <li>출처: Joseph Needham, <em>Science and Civilisation in China, Volume 3</em>, Cambridge University Press, 1959.</li> </ul> <h3 id="3-1819세기-유럽--행렬-이론의-시작">3. 18–19세기 유럽 – 행렬 이론의 시작</h3> <p><strong>Gabriel Cramer (1750)</strong>: 연립방정식의 해법으로 크래머의 공식을 제시했다.</p> <p><strong>Carl Friedrich Gauss (1800s)</strong>: <strong>가우스 소거법</strong>을 정립했다.</p> <p><strong>Augustin-Louis Cauchy (1820s)</strong>: 행렬과 행렬식 개념을 정리했다.</p> <p><strong>Arthur Cayley &amp; James Sylvester (1850s)</strong>: 오늘날 우리가 아는 행렬 개념을 형식화하고, 행렬 연산과 고유값 이론의 기초를 마련했다.</p> <ul> <li>출처: Thomas Hawkins, <em>Emergence of the Theory of Lie Groups</em>, Springer, 2000., Karen Hunger Parshall, <em>James Joseph Sylvester: Jewish Mathematician in a Victorian World</em>, Johns Hopkins University Press, 2006.</li> </ul> <h3 id="4-현대-선형대수의-형성-20세기-초중반">4. 현대 선형대수의 형성 (20세기 초~중반)</h3> <p><strong>David Hilbert</strong>, <strong>Emmy Noether</strong> 등의 수학자들이 선형대수학을 <strong>추상대수학</strong>, <strong>함수해석학</strong>과 연결시키고,특히 양자역학에서 선형대수학이 필수 수학 언어로 자리잡게 되었다.</p> <ul> <li>출처: I. M. Gelfand, <em>Lectures on Linear Algebra</em>, Dover Publications, 1989.</li> </ul> <hr/> <h2 id="선형대수학이-중요한-이유">선형대수학이 중요한 이유</h2> <ol> <li> <p>기계학습 / 딥러닝</p> <p>신경망의 가중치, 입력 데이터의 표현 등 대부분의 구성 요소가 벡터와 행렬 형태로 표현된다.</p> </li> <li> <p>컴퓨터 그래픽스</p> <p>3D 회전, 확대, 이동 등을 행렬로 표현되어있다.</p> </li> <li> <p>물리학</p> <p>양자역학 등에서 상태 표현에 벡터를 사용한다.</p> </li> <li> <p>통계 / 데이터 분석</p> <p>공분산 행렬, 주성분 분석(PCA) 등 고차원 데이터 분석에서 행렬은 핵심적인 도구로 사용된다.</p> </li> </ol> <hr/> <h2 id="앞으로-다룰-포스트">앞으로 다룰 포스트</h2> <ol> <li>선형대수학에서 주로 쓰이는 용어</li> <li>벡터와 행렬</li> <li>선형 변환</li> <li>행렬식</li> <li>외적과 내적</li> <li>고윳값과 고유벡터</li> <li>선형 방정식의 해법</li> <li>LU 변환</li> <li>가우스-조던 소거법</li> <li>고윳값 분해</li> <li>선형 회귀</li> </ol> <hr/> <p>이번 글은 선형대수학의 전반적인 개념과 역사적 배경을 정리하는 데 초점을 맞췄다. 다음 글부터는 본격적으로 개별 개념들을 자세히 다루도록 하겠다.</p>]]></content><author><name></name></author><category term="Study"/><category term="LinearAlgebra"/><category term="KR"/><summary type="html"><![CDATA[선형대수학의 서론]]></summary></entry><entry><title type="html">about-eng</title><link href="https://pelu10075.github.io/blog/2025/about-eng/" rel="alternate" type="text/html" title="about-eng"/><published>2025-06-09T23:59:59+00:00</published><updated>2025-06-09T23:59:59+00:00</updated><id>https://pelu10075.github.io/blog/2025/about-eng</id><content type="html" xml:base="https://pelu10075.github.io/blog/2025/about-eng/"><![CDATA[<p>This blog was created out of a deep interest in computer programming and aims to document and share my academic journey and exploration of areas I am passionate about. Through this space, I intend to systematically organize my learning process and reflections on various STEM topics.</p> <p>The blog will primarily focus on the following subjects:</p> <p>Linear Algebra</p> <p>Calculus</p> <p>Probability and Statistics</p> <p>Graph Theory</p> <p>Algorithms</p> <p>Programming Languages</p> <p>While the blog will be written mainly in Korean, documents will be categorized by language using the tag <code class="language-plaintext highlighter-rouge">EN</code> for English posts.</p> <p>Although I am still in the process of learning, I strive to deepen my understanding of these fields through consistent study and reflection. I hope this blog becomes a meaningful space for exchanging knowledge and insights with others who share similar interests.</p> <p>Thank you.</p>]]></content><author><name></name></author><category term="notice"/><category term="EN"/><summary type="html"><![CDATA[This is the Korean translation of about.]]></summary></entry></feed>