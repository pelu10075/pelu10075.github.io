---
layout: post
title: 선형 변환
date: 2025-06-21 00:00:00
description: 벡터를 변환하는 함수와 생성에 대해
tags: LinearAlgebra KR
categories: Study
featured: false
chart:
  chartjs: true
---

## 선형 변환 — 벡터를 바꾸는 함수

지난 포스트에선 행렬이 벡터를 변형할 수 있다는 이야기를 하였다.

이번 글에서는 '변형'이 무슨 의미인지, 그리고 왜 선형(linear)인지 설명하겠다.

---

## 선형 변환이란 무엇인가?

선형 변환(linear transformation)은 벡터를 입력으로 받아 또 다른 벡터를 출력하는 함수다.
하지만 아무 벡터 변환이나 선형 변환이 되는 것은 아니다. 반드시 두 가지 조건을 만족해야 한다.

어떤 변환 T가 선형 변환이 되려면, 임의의 벡터 u, v와 스칼라(실수) c에 대해 다음 조건이 성립해야 한다.

- 덧셈 보존: T(u + v) = T(u) + T(v)
- 스칼라 곱 보존: T(c · u) = c · T(u)

이 두 조건은 "선형성(linearity)"을 의미한다.
쉽게 말하면, 벡터들을 먼저 더한 뒤 변환한 것과 각각 변환한 뒤 더한 것이 같아야 하고,
벡터에 먼저 스칼라를 곱한 후 변환한 것과, 변환 후 스칼라를 곱한 것이 같아야 한다.

---

### 선형 변환 = 행렬 곱

선형 변환은 항상 어떤 행렬 곱으로 표현할 수 있다.
즉, T(x) = A·x 형태로 나타낼 수 있으며, 이 행렬 A가 변환의 본질이다.

따라서 선형 변환을 제대로 이해하려면, 행렬 곱의 계산 방법을 알아야 한다.

---

### 행렬 곱 계산 방법

행렬 A가 다음과 같다고 하자.

$$
A = \begin{bmatrix} a & b \\ c & d \end{bmatrix}
$$

벡터 x가 다음과 같을 때,

$$
X = \begin{bmatrix} x \\ y \end{bmatrix}
$$

곱셈 결과는 이렇게 나온다.

$$
A×X = \begin{bmatrix} a·x + b·y \\ c·x + d·y \end{bmatrix}
$$

이 계산은 컴퓨터 그래픽, 물리 시뮬레이션, 딥러닝 모델에서 매 순간 수행되는 핵심 연산이다.

---

### 선형 변환의 기하학적 의미

행렬 A는 벡터를 회전하거나, 크기를 바꾸거나, 기울이거나, 납작하게 만든다.
예를 들어, 다음 행렬은 모든 벡터를 x축으로 납작하게 누른다.

$$
A = \begin{bmatrix} 1 & 0 \\ 0 & 0 \end{bmatrix}
$$

어떤 벡터를 곱해도 결과는 y성분이 0인 벡터가 된다. 이는 모든 벡터가 x축 위로 눌린 것이다.

이처럼 행렬은 공간에 작용하며, 벡터들이 놓일 수 있는 범위를 통째로 바꾼다.

---

## 생성(Span)이란?

Span(스팬)은 어떤 벡터 집합이 생성할 수 있는 모든 선형 결합의 집합을 말한다.

이렇게 설명하면 이해하기 힘드니, 예를 들자면, 다음 두 벡터가 있다고 하자.

```plotly
{
  "data": [
    {
      "type": "scatter",
      "mode": "lines+markers+text",
      "x": [0, 1],
      "y": [0, 0],
      "line": { "color": "red", "width": 3 },
      "marker": { "size": 6 },
      "text": ["", "v₁ = [1, 0]"],
      "textposition": "top right",
      "name": "v₁"
    },
    {
      "type": "scatter",
      "mode": "lines+markers+text",
      "x": [0, 0],
      "y": [0, 1],
      "line": { "color": "blue", "width": 3 },
      "marker": { "size": 6 },
      "text": ["", "v₂ = [0, 1]"],
      "textposition": "top left",
      "name": "v₂"
    }
  ],
  "layout": {
    "title": { "text": "Unit Vectors v₁ and v₂" },
    "xaxis": { "range": [-1, 2], "zeroline": true, "title": "x" },
    "yaxis": { "range": [-1, 2], "zeroline": true, "title": "y" },
    "showlegend": false,
    "width": 500,
    "height": 500
  }
}
```

이 둘의 Span은 2차원 평면 전체다. 왜냐하면 모든 벡터는 v₁과 v₂를 적절히 곱하고 더해서 만들 수 있기 때문이다.

반대로 다음처럼 한 방향에만 있는 벡터 두 개:

```plotly
{
  "data": [
    {
      "type": "scatter",
      "mode": "lines+markers+text",
      "x": [0, 1],
      "y": [0, 0],
      "line": { "color": "red", "width": 3 },
      "marker": { "size": 6 },
      "text": ["", "v₁ = [1, 0]"],
      "textposition": "top right",
      "name": "v₁"
    },
    {
      "type": "scatter",
      "mode": "lines+markers+text",
      "x": [0, 2],
      "y": [0, 0],
      "line": { "color": "blue", "width": 3 },
      "marker": { "size": 6 },
      "text": ["", "v₂ = [2, 0]"],
      "textposition": "bottom right",
      "name": "v₂"
    }
  ],
  "layout": {
    "title": { "text": "Vectors v₁ and v₂ on the Plane" },
    "xaxis": { "range": [-1, 3], "zeroline": true, "title": "x" },
    "yaxis": { "range": [-1, 1], "zeroline": true, "title": "y" },
    "showlegend": false
  }
}
```

이들의 Span은 x축 위의 직선 하나뿐이다. 같은 방향의 벡터끼리는 더해봤자 더 넓은 공간을 만들 수 없다.

즉, 벡터들의 Span이란 그 벡터들이 **닿을 수 있는 모든 위치**의 집합이다.
이 개념은 선형 독립, 차원, 기저 등과 밀접하게 연결된다.

---

### 왜 Span과 선형 변환이 연결되는가?

어떤 행렬 A에 대해 A·x를 구한다고 했을 때,
결국 A는 자기 열벡터들의 Span 속으로 입력 벡터를 ‘보내는’ 역할을 한다.

즉, 행렬의 선형 변환 결과는 행렬 열벡터들의 Span 안에 항상 존재한다.
이 사실은 해를 갖는 연립방정식, 기저, 영공간(null space) 등을 이해할 때 핵심이 된다.

---

## 요약

- 선형 변환은 덧셈과 스칼라 곱을 보존하는 변환이며, 항상 행렬 곱으로 나타낼 수 있다.

- 행렬 곱은 공간을 회전, 변형, 축소, 투영하는 역할을 한다.

- Span은 벡터들이 만들어낼 수 있는 모든 선형 결합의 집합이다.

- 선형 변환 결과는 항상 행렬의 열벡터들의 Span 안에 위치한다.

---

선형 변환에 대해 이야기 해보기 위해 여러 예제를 만들어 보았으나, 블로그의 특성상 선형 변환이 적용되는 예시를 보여주기 어려웠다.
**3b1b**의 영상을 보고 직관적으로 이해하는 편이 학습에 도움이 될 것이라 생각한다.
다음 글에서는 선형 변환에서 중요한 개념인 **고유값(eigenvalue)**과 **고유벡터(eigenvector)**에 대해 다룬다.
특정 벡터는 선형 변환을 거쳐도 방향이 바뀌지 않고 크기만 달라지는데,
그런 벡터가 무엇이며 왜 중요한지 살펴보겠다.
